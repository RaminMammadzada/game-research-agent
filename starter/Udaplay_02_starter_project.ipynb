{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fdd0bcb",
   "metadata": {},
   "source": [
    "# [STARTER] Udaplay Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9325b035",
   "metadata": {},
   "source": [
    "## Part 02 - Agent\n",
    "\n",
    "In this part of the project, you'll use your VectorDB to be part of your Agent as a tool.\n",
    "\n",
    "You're building UdaPlay, an AI Research Agent for the video game industry. The agent will:\n",
    "1. Answer questions using internal knowledge (RAG)\n",
    "2. Search the web when needed\n",
    "3. Maintain conversation state\n",
    "4. Return structured outputs\n",
    "5. Store useful information for future use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b42de90",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a963d4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only needed for Udacity workspace\n",
    "\n",
    "import importlib.util\n",
    "import sys\n",
    "\n",
    "# Check if 'pysqlite3' is available before importing\n",
    "if importlib.util.find_spec(\"pysqlite3\") is not None:\n",
    "    import pysqlite3\n",
    "    sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fd10c06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Import the necessary libs - DONE\n",
    "import os\n",
    "from typing import List, Dict, Any, Optional, TypedDict\n",
    "from dotenv import load_dotenv\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "from tavily import TavilyClient\n",
    "\n",
    "from lib.agents import Agent, AgentState\n",
    "from lib.llm import LLM\n",
    "from lib.messages import UserMessage, SystemMessage, ToolMessage, AIMessage\n",
    "from lib.tooling import Tool\n",
    "from lib.state_machine import StateMachine, Step, EntryPoint, Termination, Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "87e465d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Load environment variables - DONE\n",
    "load_dotenv()\n",
    "\n",
    "# OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "# TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")\n",
    "\n",
    "# Initialize Clients\n",
    "embedding_fn = embedding_functions.OpenAIEmbeddingFunction(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "chroma_client = chromadb.PersistentClient(path=\"./chroma_db\")\n",
    "collection = chroma_client.get_collection(name=\"udaplay\", embedding_function=embedding_fn)\n",
    "tavily_client = TavilyClient(api_key=os.getenv(\"TAVILY_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce364221",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "27de4729",
   "metadata": {},
   "source": [
    "### Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ab2dac",
   "metadata": {},
   "source": [
    "Build at least 3 tools:\n",
    "- retrieve_game: To search the vector DB\n",
    "- evaluate_retrieval: To assess the retrieval performance\n",
    "- game_web_search: If no good, search the web\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4f14cd",
   "metadata": {},
   "source": [
    "#### Retrieve Game Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b25c36dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create retrieve_game tool - DONE\n",
    "import re\n",
    "\n",
    "\n",
    "def retrieve_game(query: str) -> str:\n",
    "    \"\"\"Semantic search: Find relevant games in the vector DB.\"\"\"\n",
    "    print(f\"DEBUG: Retrieving for query: {query}\")\n",
    "\n",
    "    results = collection.query(query_texts=[query], n_results=3)\n",
    "    docs = results[\"documents\"][0]\n",
    "    metas = results[\"metadatas\"][0]\n",
    "\n",
    "    context_parts: List[str] = []\n",
    "    for doc, meta in zip(docs, metas):\n",
    "        name = meta.get(\"Name\")\n",
    "        platform = meta.get(\"Platform\")\n",
    "        year = meta.get(\"YearOfRelease\")\n",
    "        context_parts.append(\n",
    "            f\"Game: {name} ({platform}, {year})\\n\"\n",
    "            f\"Genre: {meta.get('Genre')}\\n\"\n",
    "            f\"Publisher: {meta.get('Publisher')}\\n\"\n",
    "            f\"Description: {meta.get('Description')}\\n\"\n",
    "        )\n",
    "\n",
    "    return \"\\n\\n\".join(context_parts)\n",
    "\n",
    "\n",
    "retrieve_tool = Tool(retrieve_game)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910dc945",
   "metadata": {},
   "source": [
    "#### Evaluate Retrieval Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0d9d014b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create evaluate_retrieval tool - DONE\n",
    "\n",
    "import re\n",
    "\n",
    "\n",
    "def _looks_like_followup(question: str) -> bool:\n",
    "    q = f\" {question.strip().lower()} \"\n",
    "    followup_markers = [\n",
    "        \" it \",\n",
    "        \" its \",\n",
    "        \" this \",\n",
    "        \" that \",\n",
    "        \" this game \",\n",
    "        \" that game \",\n",
    "        \" the game \",\n",
    "    ]\n",
    "    return any(m in q for m in followup_markers)\n",
    "\n",
    "\n",
    "def _is_time_sensitive(question: str) -> bool:\n",
    "    q = question.lower()\n",
    "    return any(k in q for k in [\"latest\", \"news\", \"current\", \"today\", \"recent\", \"update\", \"updates\"])\n",
    "\n",
    "\n",
    "def _normalize(text: str) -> str:\n",
    "    return re.sub(r\"\\s+\", \" \", (text or \"\").lower()).strip()\n",
    "\n",
    "\n",
    "def _keyword_overlap(question: str, retrieved_docs: str) -> bool:\n",
    "    q = _normalize(question)\n",
    "    d = _normalize(retrieved_docs)\n",
    "\n",
    "    stop = {\n",
    "        \"what\", \"when\", \"where\", \"who\", \"which\", \"is\", \"was\", \"were\", \"a\", \"an\", \"the\",\n",
    "        \"for\", \"to\", \"of\", \"on\", \"in\", \"and\", \"or\", \"about\", \"released\", \"release\",\n",
    "        \"game\", \"tell\", \"me\", \"it\", \"its\", \"this\", \"that\",\n",
    "    }\n",
    "\n",
    "    words = [w for w in re.findall(r\"[a-z0-9']+\", q) if w not in stop and len(w) >= 3]\n",
    "\n",
    "    # If question contains an obvious franchise token, require it in retrieved docs.\n",
    "    franchise_tokens = [\"mario\", \"pokemon\", \"gran\", \"turismo\", \"gta\", \"ragnarok\", \"mortal\", \"kombat\"]\n",
    "    if any(t in q for t in franchise_tokens):\n",
    "        return any(t in d for t in franchise_tokens if t in q)\n",
    "\n",
    "    # Otherwise require some overlap on meaningful words.\n",
    "    return any(w in d for w in words)\n",
    "\n",
    "\n",
    "def evaluate_retrieval(question: str, retrieved_docs: str) -> str:\n",
    "    \"\"\"Decide if the retrieved docs are sufficient to answer the question.\"\"\"\n",
    "    print(\"DEBUG: Evaluating context\")\n",
    "\n",
    "    if not retrieved_docs or \"Game:\" not in retrieved_docs:\n",
    "        return \"NO\"\n",
    "\n",
    "    # Time-sensitive requests should go to web.\n",
    "    if _is_time_sensitive(question):\n",
    "        return \"NO\"\n",
    "\n",
    "    # Special handling: GTA 6 should not be answered from older GTA entries.\n",
    "    qn = _normalize(question)\n",
    "    if \"gta 6\" in qn or \"gta vi\" in qn or \"grand theft auto 6\" in qn or \"grand theft auto vi\" in qn:\n",
    "        dn = _normalize(retrieved_docs)\n",
    "        if (\"6\" not in dn) and (\"vi\" not in dn):\n",
    "            return \"NO\"\n",
    "\n",
    "    # Follow-ups (\"it/this game\") are acceptable if we retrieved any specific game block.\n",
    "    if _looks_like_followup(question):\n",
    "        return \"YES\"\n",
    "\n",
    "    # Heuristic overlap check\n",
    "    if _keyword_overlap(question, retrieved_docs):\n",
    "        return \"YES\"\n",
    "\n",
    "    # LLM fallback (robust prompt)\n",
    "    llm = LLM(model=\"gpt-3.5-turbo\", temperature=0.0)\n",
    "    prompt = f\"\"\"\n",
    "You are an evaluator for a RAG agent.\n",
    "\n",
    "Decide if the Retrieved Docs contain enough information to answer the Question.\n",
    "\n",
    "Guidance:\n",
    "- Answer YES if the docs mention the same game/franchise and include the needed fact.\n",
    "- Answer NO if the docs are about a different game/franchise OR if the question asks for time-sensitive \"latest news\".\n",
    "- Return ONLY: YES or NO\n",
    "\n",
    "Question: {question}\n",
    "Retrieved Docs:\n",
    "{retrieved_docs}\n",
    "\"\"\"\n",
    "\n",
    "    response = llm.invoke([UserMessage(content=prompt)])\n",
    "    return (response.content or \"\").strip().upper()\n",
    "\n",
    "\n",
    "evaluate_tool = Tool(evaluate_retrieval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7935a26",
   "metadata": {},
   "source": [
    "#### Game Web Search Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2ad698aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create game_web_search tool - DONE\n",
    "def game_web_search(question: str) -> str:\n",
    "    \"\"\"\n",
    "    Semantic search: Finds most results in the vector DB (Fallback to web)\n",
    "    \"\"\"\n",
    "    print(f\"DEBUG: Web searching for: {question}\")\n",
    "    try:\n",
    "        response = tavily_client.search(question, search_depth=\"advanced\")\n",
    "        context = \"\"\n",
    "        for result in response['results']:\n",
    "            context += f\"Title: {result['title']}\\nContent: {result['content']}\\nURL: {result['url']}\\n\\n\"\n",
    "        return context\n",
    "    except Exception as e:\n",
    "        return f\"Error searching web: {e}\"\n",
    "\n",
    "search_tool = Tool(game_web_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df844b3b",
   "metadata": {},
   "source": [
    "### Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "31c56281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create your Agent abstraction using StateMachine - DONE\n",
    "import re\n",
    "\n",
    "class ResearchAgentState(AgentState):\n",
    "    retrieved_context: Optional[str]\n",
    "    evaluation_result: Optional[str]\n",
    "    source: Optional[str]\n",
    "\n",
    "class ResearchAgent(Agent):\n",
    "    def __init__(self, model_name=\"gpt-3.5-turbo\", temperature=0.7):\n",
    "        super().__init__(model_name, \"You are a game research assistant.\", temperature=temperature)\n",
    "    \n",
    "    def _extract_game_from_history(self, messages) -> Optional[str]:\n",
    "        \"\"\"Extract the most recently mentioned game from conversation history.\"\"\"\n",
    "        for msg in reversed(messages):\n",
    "            if isinstance(msg, AIMessage):\n",
    "                content = msg.content\n",
    "                # Look for known game patterns\n",
    "                patterns = [\n",
    "                    r'(Super Mario 64)',\n",
    "                    r'(Gran Turismo(?:\\s*\\d*)?)',\n",
    "                    r'(Pokémon [A-Za-z\\s]+)',\n",
    "                    r\"(Marvel's Spider-Man(?:\\s*\\d*)?)\",\n",
    "                    r'(Grand Theft Auto[:\\s]+[A-Za-z\\s]+)',\n",
    "                    r'(Minecraft)',\n",
    "                    r'(Wii Sports)',\n",
    "                    r'(Mario Kart[:\\s]*\\d*[A-Za-z\\s]*)',\n",
    "                ]\n",
    "                for pattern in patterns:\n",
    "                    match = re.search(pattern, content, re.IGNORECASE)\n",
    "                    if match:\n",
    "                        return match.group(1).strip()\n",
    "        return None\n",
    "    \n",
    "    def _is_followup_query(self, query: str) -> bool:\n",
    "        \"\"\"Check if query is a follow-up referencing previous context.\"\"\"\n",
    "        followup_indicators = [\n",
    "            'it', 'this game', 'that game', 'the game', 'its', 'this',\n",
    "            'who is the main', 'what year', 'when was it', 'was it', 'what platform'\n",
    "        ]\n",
    "        query_lower = query.lower()\n",
    "        for indicator in followup_indicators:\n",
    "            if indicator in query_lower:\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    def _format_conversation_history(self, messages) -> str:\n",
    "        \"\"\"Format conversation history for context.\"\"\"\n",
    "        history_parts = []\n",
    "        for msg in messages:\n",
    "            if isinstance(msg, AIMessage):\n",
    "                history_parts.append(f\"Previous answer: {msg.content[:300]}\")\n",
    "        return \"\\n\".join(history_parts[-3:]) if history_parts else \"\"\n",
    "        \n",
    "    def _retrieve_step(self, state: ResearchAgentState) -> ResearchAgentState:\n",
    "        query = state[\"user_query\"]\n",
    "        messages = state.get(\"messages\", [])\n",
    "        \n",
    "        # Check if this is a follow-up query and expand it with game name from context\n",
    "        if self._is_followup_query(query):\n",
    "            game_name = self._extract_game_from_history(messages)\n",
    "            if game_name:\n",
    "                query = f\"{game_name}: {query}\"\n",
    "                print(f\"DEBUG: Expanded follow-up to: {query}\")\n",
    "        \n",
    "        print(f\"DEBUG: Retrieving for query: {query}\")\n",
    "        context = retrieve_game(query)\n",
    "        return {**state, \"retrieved_context\": context, \"source\": \"internal\"}\n",
    "\n",
    "    def _evaluate_step(self, state: ResearchAgentState) -> ResearchAgentState:\n",
    "        query = state[\"user_query\"]\n",
    "        context = state[\"retrieved_context\"]\n",
    "        print(f\"DEBUG: Evaluating context\")\n",
    "        result = evaluate_retrieval(query, context)\n",
    "        return {**state, \"evaluation_result\": result}\n",
    "\n",
    "    def _web_search_step(self, state: ResearchAgentState) -> ResearchAgentState:\n",
    "        query = state[\"user_query\"]\n",
    "        print(f\"DEBUG: Web searching for: {query}\")\n",
    "        context = game_web_search(query)\n",
    "        return {**state, \"retrieved_context\": context, \"source\": \"web\"}\n",
    "\n",
    "    def _generate_answer_step(self, state: ResearchAgentState) -> ResearchAgentState:\n",
    "        query = state[\"user_query\"]\n",
    "        context = state[\"retrieved_context\"]\n",
    "        source = state[\"source\"]\n",
    "        messages = state.get(\"messages\", [])\n",
    "        \n",
    "        # Include conversation history for LLM context\n",
    "        history = self._format_conversation_history(messages)\n",
    "        history_section = f\"\\nConversation History:\\n{history}\\n\" if history else \"\"\n",
    "        \n",
    "        prompt_content = f\"\"\"You are a game research assistant. Answer based on the context.\n",
    "{history_section}\n",
    "Context ({source}): \n",
    "{context}\n",
    "\n",
    "Question: {query}\n",
    "\n",
    "Instructions:\n",
    "- Provide a complete answer in 2-4 sentences\n",
    "- If a follow-up, use conversation history to determine which game\n",
    "- Include: Game Name (Platform, Year)\n",
    "\"\"\"\n",
    "        \n",
    "        new_user_message = UserMessage(content=prompt_content)\n",
    "        messages_for_llm = messages + [new_user_message]\n",
    "        \n",
    "        llm = LLM(model=self.model_name, temperature=self.temperature)\n",
    "        response = llm.invoke(messages_for_llm)\n",
    "        \n",
    "        return {**state, \"messages\": messages + [new_user_message, AIMessage(content=response.content)]}\n",
    "\n",
    "    def _create_state_machine(self) -> StateMachine[ResearchAgentState]:\n",
    "        machine = StateMachine[ResearchAgentState](ResearchAgentState)\n",
    "        \n",
    "        entry = EntryPoint[ResearchAgentState]()\n",
    "        retrieve = Step[ResearchAgentState](\"retrieve\", self._retrieve_step)\n",
    "        evaluate = Step[ResearchAgentState](\"evaluate\", self._evaluate_step)\n",
    "        web_search = Step[ResearchAgentState](\"web_search\", self._web_search_step)\n",
    "        generate = Step[ResearchAgentState](\"generate\", self._generate_answer_step)\n",
    "        termination = Termination[ResearchAgentState]()\n",
    "        \n",
    "        machine.add_steps([entry, retrieve, evaluate, web_search, generate, termination])\n",
    "        \n",
    "        machine.connect(entry, retrieve)\n",
    "        machine.connect(retrieve, evaluate)\n",
    "        \n",
    "        def check_eval(state: ResearchAgentState) -> str:\n",
    "            return \"generate\" if \"YES\" in state[\"evaluation_result\"] else \"web_search\"\n",
    "        \n",
    "        machine.connect(evaluate, [generate, web_search], condition=check_eval)\n",
    "        machine.connect(web_search, generate)\n",
    "        machine.connect(generate, termination)\n",
    "        \n",
    "        return machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0ec23893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Query: When Pokémon Gold and Silver was released? ---\n",
      "[StateMachine] Starting: __entry__\n",
      "DEBUG: Retrieving for query: When Pokémon Gold and Silver was released?\n",
      "DEBUG: Retrieving for query: When Pokémon Gold and Silver was released?\n",
      "[StateMachine] Executing step: retrieve\n",
      "DEBUG: Evaluating context\n",
      "DEBUG: Evaluating context\n",
      "[StateMachine] Executing step: evaluate\n",
      "[StateMachine] Executing step: generate\n",
      "[StateMachine] Terminating: __termination__\n",
      "Answer: Pokémon Gold and Silver was released for the Game Boy Color in 1999.\n",
      "\n",
      "--- Query: Which one was the first 3D platformer Mario game? ---\n",
      "[StateMachine] Starting: __entry__\n",
      "DEBUG: Retrieving for query: Which one was the first 3D platformer Mario game?\n",
      "DEBUG: Retrieving for query: Which one was the first 3D platformer Mario game?\n",
      "[StateMachine] Executing step: retrieve\n",
      "DEBUG: Evaluating context\n",
      "DEBUG: Evaluating context\n",
      "[StateMachine] Executing step: evaluate\n",
      "[StateMachine] Executing step: generate\n",
      "[StateMachine] Terminating: __termination__\n",
      "Answer: The first 3D platformer Mario game was Super Mario 64, released for the Nintendo 64 in 1996.\n",
      "\n",
      "--- Query: Was Mortal Kombat X realeased for Playstation 5? ---\n",
      "[StateMachine] Starting: __entry__\n",
      "DEBUG: Retrieving for query: Was Mortal Kombat X realeased for Playstation 5?\n",
      "DEBUG: Retrieving for query: Was Mortal Kombat X realeased for Playstation 5?\n",
      "[StateMachine] Executing step: retrieve\n",
      "DEBUG: Evaluating context\n",
      "DEBUG: Evaluating context\n",
      "[StateMachine] Executing step: evaluate\n",
      "DEBUG: Web searching for: Was Mortal Kombat X realeased for Playstation 5?\n",
      "DEBUG: Web searching for: Was Mortal Kombat X realeased for Playstation 5?\n",
      "[StateMachine] Executing step: web_search\n",
      "[StateMachine] Executing step: generate\n",
      "[StateMachine] Terminating: __termination__\n",
      "Answer: Mortal Kombat X was released for PlayStation 4 on April 14, 2015, but it was not specifically released for PlayStation 5.\n"
     ]
    }
   ],
   "source": [
    "# TODO: Invoke your agent - DONE\n",
    "agent = ResearchAgent()\n",
    "\n",
    "queries = [\n",
    "    \"When Pokémon Gold and Silver was released?\",\n",
    "    \"Which one was the first 3D platformer Mario game?\",\n",
    "    \"Was Mortal Kombat X realeased for Playstation 5?\"\n",
    "]\n",
    "\n",
    "for query in queries:\n",
    "    print(f\"\\n--- Query: {query} ---\")\n",
    "    run = agent.invoke(query)\n",
    "    print(f\"Answer: {run.get_final_state()['messages'][-1].content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a55081",
   "metadata": {},
   "source": [
    "### (Optional) Advanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb83fbb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[StateMachine] Starting: __entry__\n",
      "DEBUG: Retrieving for query: What is the release date of GTA 6?\n",
      "[StateMachine] Executing step: retrieve\n",
      "DEBUG: Evaluating context\n",
      "[StateMachine] Executing step: evaluate\n",
      "DEBUG: Web searching for: What is the release date of GTA 6?\n",
      "[StateMachine] Executing step: web_search\n",
      "DEBUG: Memorizing new info about 'What is the release date of GTA 6?'\n",
      "[StateMachine] Executing step: generate\n",
      "[StateMachine] Terminating: __termination__\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Run('335fbdc5-d717-4698-9cef-abde152d5cff')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Update your agent with long-term memory - DONE\n",
    "# TODO: Convert the agent to be a state machine, with the tools being pre-defined nodes - DONE\n",
    "\n",
    "class LearningResearchAgent(ResearchAgent):\n",
    "    def _generate_answer_step(self, state: ResearchAgentState) -> ResearchAgentState:\n",
    "        # Generate answer using parent logic\n",
    "        new_state = super()._generate_answer_step(state)\n",
    "        \n",
    "        # Long-term memory: Save web results to ChromaDB\n",
    "        if new_state[\"source\"] == \"web\":\n",
    "            print(f\"DEBUG: Memorizing new info about '{new_state['user_query']}'\")\n",
    "            try:\n",
    "                collection.add(\n",
    "                    ids=[f\"memory_{abs(hash(new_state['user_query']))}\"],\n",
    "                    documents=[f\"Q: {new_state['user_query']}\\nA: {new_state['messages'][-1].content}\"],\n",
    "                    metadatas=[{\"Name\": \"Learned Memory\", \"Platform\": \"Web\", \"YearOfRelease\": 2025}]\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f\"DEBUG: Memory update skipped: {e}\")\n",
    "        return new_state\n",
    "\n",
    "# Test the learning agent\n",
    "learning_agent = LearningResearchAgent()\n",
    "learning_agent.invoke(\"What is the release date of GTA 6?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1cba6275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Query: Who developed Gran Turismo? ---\n",
      "[StateMachine] Starting: __entry__\n",
      "DEBUG: Retrieving for query: Who developed Gran Turismo?\n",
      "[StateMachine] Executing step: retrieve\n",
      "DEBUG: Evaluating context\n",
      "[StateMachine] Executing step: evaluate\n",
      "[StateMachine] Executing step: generate\n",
      "[StateMachine] Terminating: __termination__\n",
      "Final Answer:\n",
      "Gran Turismo was developed by Sony Computer Entertainment. (Source: Context)\n",
      "Source: internal\n",
      "\n",
      "--- Query: When was God of War Ragnarok released? ---\n",
      "[StateMachine] Starting: __entry__\n",
      "DEBUG: Retrieving for query: When was God of War Ragnarok released?\n",
      "[StateMachine] Executing step: retrieve\n",
      "DEBUG: Evaluating context\n",
      "[StateMachine] Executing step: evaluate\n",
      "DEBUG: Web searching for: When was God of War Ragnarok released?\n",
      "[StateMachine] Executing step: web_search\n",
      "[StateMachine] Executing step: generate\n",
      "[StateMachine] Terminating: __termination__\n",
      "Final Answer:\n",
      "God of War Ragnarok was released on November 9, 2022. (Source: https://www.playstation.com/en-us/games/god-of-war-ragnarok/)\n",
      "Source: web\n",
      "\n",
      "--- Query: What is the latest news about GTA 6? ---\n",
      "[StateMachine] Starting: __entry__\n",
      "DEBUG: Retrieving for query: What is the latest news about GTA 6?\n",
      "[StateMachine] Executing step: retrieve\n",
      "DEBUG: Evaluating context\n",
      "[StateMachine] Executing step: evaluate\n",
      "DEBUG: Web searching for: What is the latest news about GTA 6?\n",
      "[StateMachine] Executing step: web_search\n",
      "[StateMachine] Executing step: generate\n",
      "[StateMachine] Terminating: __termination__\n",
      "Final Answer:\n",
      "The latest news about GTA 6 is that its release date is set for November 19, 2026. (Source: https://www.rockstargames.com/newswire/article/ak3ak31a49a221/grand-theft-auto-vi-is-now-set-to-launch-november-19-2026)\n",
      "Source: web\n"
     ]
    }
   ],
   "source": [
    "# Initialize Agent\n",
    "agent = ResearchAgent()\n",
    "\n",
    "# Test Queries\n",
    "queries = [\n",
    "    \"Who developed Gran Turismo?\",\n",
    "    \"When was God of War Ragnarok released?\",\n",
    "    \"What is the latest news about GTA 6?\"\n",
    "]\n",
    "\n",
    "for query in queries:\n",
    "    print(f\"\\n--- Query: {query} ---\")\n",
    "    run = agent.invoke(query)\n",
    "    final_state = run.get_final_state()\n",
    "    print(f\"Final Answer:\\n{final_state['messages'][-1].content}\")\n",
    "    print(f\"Source: {final_state.get('source')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8710e6af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Session Management Demo ===\n",
      "\n",
      "--- Session 1: Super Mario 64 Context ---\n",
      "[StateMachine] Starting: __entry__\n",
      "DEBUG: Retrieving for query: Tell me about Super Mario 64.\n",
      "DEBUG: Retrieving for query: Tell me about Super Mario 64.\n",
      "[StateMachine] Executing step: retrieve\n",
      "DEBUG: Evaluating context\n",
      "DEBUG: Evaluating context\n",
      "[StateMachine] Executing step: evaluate\n",
      "[StateMachine] Executing step: generate\n",
      "[StateMachine] Terminating: __termination__\n",
      "[StateMachine] Starting: __entry__\n",
      "DEBUG: Expanded follow-up to: Super Mario 64: What year was it released?\n",
      "DEBUG: Retrieving for query: Super Mario 64: What year was it released?\n",
      "DEBUG: Retrieving for query: Super Mario 64: What year was it released?\n",
      "[StateMachine] Executing step: retrieve\n",
      "DEBUG: Evaluating context\n",
      "DEBUG: Evaluating context\n",
      "[StateMachine] Executing step: evaluate\n",
      "[StateMachine] Executing step: generate\n",
      "[StateMachine] Terminating: __termination__\n",
      "Session 1 Follow-up: Super Mario 64 was released in 1996 for the Nintendo 64.\n",
      "\n",
      "--- Session 2: Gran Turismo Context ---\n",
      "[StateMachine] Starting: __entry__\n",
      "DEBUG: Retrieving for query: Tell me about Gran Turismo.\n",
      "DEBUG: Retrieving for query: Tell me about Gran Turismo.\n",
      "[StateMachine] Executing step: retrieve\n",
      "DEBUG: Evaluating context\n",
      "DEBUG: Evaluating context\n",
      "[StateMachine] Executing step: evaluate\n",
      "[StateMachine] Executing step: generate\n",
      "[StateMachine] Terminating: __termination__\n",
      "[StateMachine] Starting: __entry__\n",
      "DEBUG: Expanded follow-up to: Gran Turismo: What year was it released?\n",
      "DEBUG: Retrieving for query: Gran Turismo: What year was it released?\n",
      "DEBUG: Retrieving for query: Gran Turismo: What year was it released?\n",
      "[StateMachine] Executing step: retrieve\n",
      "DEBUG: Evaluating context\n",
      "DEBUG: Evaluating context\n",
      "[StateMachine] Executing step: evaluate\n",
      "[StateMachine] Executing step: generate\n",
      "[StateMachine] Terminating: __termination__\n",
      "Session 2 Follow-up: Gran Turismo was released in 1997 for the PlayStation 1, setting a new standard for realistic racing simulators.\n",
      "\n",
      "--- Session 1: Context Verification ---\n",
      "[StateMachine] Starting: __entry__\n",
      "DEBUG: Expanded follow-up to: Super Mario 64: Who is the main character in this game?\n",
      "DEBUG: Retrieving for query: Super Mario 64: Who is the main character in this game?\n",
      "DEBUG: Retrieving for query: Super Mario 64: Who is the main character in this game?\n",
      "[StateMachine] Executing step: retrieve\n",
      "DEBUG: Evaluating context\n",
      "DEBUG: Evaluating context\n",
      "[StateMachine] Executing step: evaluate\n",
      "[StateMachine] Executing step: generate\n",
      "[StateMachine] Terminating: __termination__\n",
      "Session 1 Verification: The main character in Super Mario 64 (Nintendo 64, 1996) is Mario. Players control Mario as he navigates through various levels in Princess Peach's castle to rescue her from Bowser. Mario's quest to collect Power Stars and defeat enemies is the central focus of the game.\n",
      "\n",
      "--- Session 2: Independent Context Verification ---\n",
      "[StateMachine] Starting: __entry__\n",
      "DEBUG: Expanded follow-up to: Gran Turismo: What platform is this game on?\n",
      "DEBUG: Retrieving for query: Gran Turismo: What platform is this game on?\n",
      "DEBUG: Retrieving for query: Gran Turismo: What platform is this game on?\n",
      "[StateMachine] Executing step: retrieve\n",
      "DEBUG: Evaluating context\n",
      "DEBUG: Evaluating context\n",
      "[StateMachine] Executing step: evaluate\n",
      "[StateMachine] Executing step: generate\n",
      "[StateMachine] Terminating: __termination__\n",
      "Session 2 Verification: Gran Turismo was originally released on the PlayStation 1 in 1997, making it available exclusively on the PlayStation platform.\n"
     ]
    }
   ],
   "source": [
    "# Demonstrate Session Management with games in the database\n",
    "print(\"\\n=== Session Management Demo ===\")\n",
    "\n",
    "# Session 1: Ask about Super Mario 64 (in database - 009.json)\n",
    "print(\"\\n--- Session 1: Super Mario 64 Context ---\")\n",
    "agent.invoke(\"Tell me about Super Mario 64.\", session_id=\"session_1\")\n",
    "run1 = agent.invoke(\"What year was it released?\", session_id=\"session_1\")\n",
    "print(f\"Session 1 Follow-up: {run1.get_final_state()['messages'][-1].content}\")\n",
    "\n",
    "# Session 2: Ask about Gran Turismo (in database - 001.json)  \n",
    "print(\"\\n--- Session 2: Gran Turismo Context ---\")\n",
    "agent.invoke(\"Tell me about Gran Turismo.\", session_id=\"session_2\")\n",
    "run2 = agent.invoke(\"What year was it released?\", session_id=\"session_2\")\n",
    "print(f\"Session 2 Follow-up: {run2.get_final_state()['messages'][-1].content}\")\n",
    "\n",
    "# Verify Session 1 context is preserved (should still reference Super Mario 64)\n",
    "print(\"\\n--- Session 1: Context Verification ---\")\n",
    "run3 = agent.invoke(\"Who is the main character in this game?\", session_id=\"session_1\")\n",
    "print(f\"Session 1 Verification: {run3.get_final_state()['messages'][-1].content}\")\n",
    "\n",
    "# Verify Session 2 stays on Gran Turismo (no cross-contamination from Session 1)\n",
    "print(\"\\n--- Session 2: Independent Context Verification ---\")\n",
    "run4 = agent.invoke(\"What platform is this game on?\", session_id=\"session_2\")\n",
    "print(f\"Session 2 Verification: {run4.get_final_state()['messages'][-1].content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b20331f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
